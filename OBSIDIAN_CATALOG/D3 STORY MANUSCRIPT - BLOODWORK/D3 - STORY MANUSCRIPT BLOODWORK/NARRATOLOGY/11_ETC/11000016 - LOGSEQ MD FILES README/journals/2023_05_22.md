  public:: true
  
- # Invoke AI can be used to merge multiple models
- # Prototyping
	- Prototype dataset based on nitrosoke
		- 1 image -> 100 steps
		- 10 images -> 1000 steps
		- Examples of training
			- ![image.png](../assets/image_1684807131473_0.png)
			- https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c8008ece-1087-4be4-88c9-bf2dd3de2b00/width=525/c8008ece-1087-4be4-88c9-bf2dd3de2b00.jpeg
			-
	-
---
	- **Nested/Merging Models**
		- Female Body as an example
		- We can break down the anatomy of a body to their artistic minimums using Anatomy books
		- For an example classification higherarchy
		- Body -> Torso -> Upper Torso -> Arm -> Upper Arm -> Bicep -> Tricep
		- At each one of these steps, one can have several variables to manipulate, each variable representing a micro-model that was trained
		- Ultimately, we'll have upper level weights to adjust the body type variation that will control several classes in itself.
		- The idea is to create a robust character creator engine.
	- fucked up workflow of this dude lol
		- ![image.png](../assets/image_1684806214390_0.png)
		-
	-
- # Creating an Ideal Dataset for Dreambooth
	- ## From what I understand, Dreambooth uses multiple 25x25 images to create a model
	- The original parameters ask for 25 images. (creator states 50 is too many)
	- I will go for 35 for my run.
	- After that she uses 5 different 'training models' to capture the subject
	-
---
	- After doing more research, that Bluedream lady just kinda used her 'guide' as a method to sell her services.
	- It did have some good information, explained easily, so not all is bad. However, there is a sense of 'withholding key information' especially in the last training model she used with that 3rd party program.
	-
---
	- Here are some better guides I found
	- [Joe Penna Dreambooth Guide](https://github.com/JoePenna/Dreambooth-Stable-Diffusion)
		- A relatively straightforward guide, his monetization is simply pushing people to his GPU hosting service. Luckily I have my own 3090.
	- [Nitrosoke's Dreambooth Method](https://github.com/nitrosocke/dreambooth-training-guide)
		- Simple. Comprehensive. Chef's Kiss.
		- #### Key Takeaways
			- The number of images used to train a model depends.
			- He specifically talks about 'style-training' when going for a specific type of art style
			- 10-100 images per style? lol. Idk what this means
			- **100 steps per sample image**
	- A lot of models have licensing that is restrictive.
	- I think I can build my own proprietary models.
	- Styles
	- Framing
	- Camera
	- Characters
	- Objects
-
---
- ## Merging models
	- A lot of models are now intertextual combinations of previous models
	- I can study these styles and perhaps prune it down to be a little more akin to my needs
	- ![image.png](../assets/image_1684800640651_0.png)
	- The way I see it, models are simply hierarchical components of a whole.
	- Art already has a way of doing this.
-
	-
- # Trauma Club
	- the kids at an elementary school who experienced a school shooting and survived have a shared trauma
	- its very difficult for them to be real children, make friends, and enjoy life as it should be.
	- however, the one thing they have is each other.
	- the only ones who understand what each other has been through, as long as they're together they have a semblance of happiness, life, love, and family
- # General Conclusions to SD Study
	-
	  public:: true
	- I can create my own models by merging other people's, and using dreambooth to create specific keywords associated those creations.
		- EG: props, specific styles, architecture, characters, etc
	- There are already a lot of good checkpoints out there that specialize in sci-fi, pretty people, etc.
	- If I run into issues creating general aliens like Grunt or Mordin, I can easily use dreambooth (thats the idea ayway)
	- CinemaDiffusion - I can create models specific to cameras either using LoRA or hypernetworks.
	- Dancing is definitely possible. It might take some engineering but I believe I can use it with flowframe, controlnet, etc
	- I believe it is also possible to do multiple people dancing in one screen, I would just need to mess with some inpainting, perhaps create models based on each of the poses inbetween the dance moves.
	- As for the fighting, I believe gunfights will be pretty easy to use, perhaps I should do some img2img research to capture exact frames of the fight.
	- *My largest concern now is regarding the maximum length of a prompt*
		- My theoretical solution is to lower the wordcount by combining and nesting models if it is an issue.
		-
- # Private GPT to use as a private librarian
	- [PrivateGPT]({{video https://www.youtube.com/watch?v=A3F5riM5BNE}})
	-
- # AI Stable Diffusion Study
	- ## A short guide on how different parts of AI nest inside each other
		- ![image.png](../assets/image_1684750774717_0.png)
-
---
	- [Basic Workflow Guide](https://stable-diffusion-art.com/workflow/)
	-
	- [Inpainting](https://stable-diffusion-art.com/inpainting_basics/)
		- A way to mask and fix problem areas like fingers
	- [Dreambooth](https://docs.google.com/document/d/1xHSHEohmCOLlhdCY0ox4EARFKKU29XbFd8ji8UgjGn4/edit)
		- This is a guide to use Dreambooth, a way to create my own characters using references.
	- [ControlNet](https://stable-diffusion-art.com/controlnet/)
		- Can detect human poses.
		- I can use this to frame by frame the dance and even choreographic scenes
	- [VAE](https://stable-diffusion-art.com/how-to-use-vae/)
		- A way to fix faces
	- [Regional Prompter](https://stable-diffusion-art.com/regional-prompter/)
		- A way to alter images by identifying specific regions to change
	- [Flowframe](https://nmkd.itch.io/flowframes)
		- interpolates video predicting and adding frames
	- [Cinematic Diffusion](https://civitai.com/models/3091/cinematic-diffusion)
		- Model for creating cinematic forms
	- [Cinediffusion](https://civitai.com/models/50000/cine-diffusion)
		- More popular cinematic model
	- [Apparel Creation](https://stable-diffusion-art.com/4-methods-to-generate-fashion-ideas-with-image-ai/)
		- This is just a guide how this dude uses inpainting to create fashion items
	- [Outpainting](https://stable-diffusion-art.com/outpainting/)
		- A method to extend an image beyond its original size
	- [Using Chat GPT as a way to make prompts](https://stable-diffusion-art.com/chatgpt-prompt/)
	- [Negative Prompts](https://stable-diffusion-art.com/how-to-use-negative-prompts/)
		- Self explanitory
	- [LoRA models](https://stable-diffusion-art.com/lora/)
		- Microscopic changes to checkpoint models to nudge SD in a certain direction
	- [SDXL](https://stable-diffusion-art.com/sdxl-beta/)
		- the next version of SD released in beta
	- [hypernetworks](https://stable-diffusion-art.com/hypernetwork/)
		- Similar to LoRA, hypternetwork is a method of training a checkpoint model.
		- The guy uses it as a stylistic method of turning certain images into a comic stylings vs turning a person into water
- # Song Design Research
	- ## What Skrillex new album teaches
		- ![image.png](../assets/image_1684740109812_0.png)
		- ![image.png](../assets/image_1684740119825_0.png)
		- Monophonic Vocals
	- ## Check Youtube for VST plugins
		- [Upright Piano](https://vis.versilstudios.com/upright-1.html)
		-
- # Internet Marketing products
	- Metal Detectors
	-
